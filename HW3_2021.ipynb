{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "colab": {
      "name": "HW3_2021.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3pK__73sQYq"
      },
      "source": [
        "**TDA233 / DIT381: Home Assignment 3 (20 points)** <br />\n",
        "**Goal: Image classification using fully-connected and convolutional neural networks, and time series prediction using recurrent neural networks** <br />\n",
        "                  **Grader: Hampus Gummesson Svensson** <br />\n",
        "                    **Due Date: 5/3** <br />\n",
        "                  **Submitted by: Name, Personal no., email** <br />\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zPqa5DWsQY8"
      },
      "source": [
        "# Read this before starting\n",
        "\n",
        "## General guielines \n",
        "*   Your name, personal number and email address should be specified above.\n",
        "*   All solutions to theoretical and pratical problems must be submitted in this ipynb notebook, and equations wherever required, should be formatted using LaTeX math-mode.\n",
        "*   All the answers for theoretical questions and text-based practical questions must be filled in the cells created for you with \"Your answer here:\" below each question, but feel free to add more cells if needed.\n",
        "*   All discussion regarding practical problems, along with solutions and plots should be specified in this notebook. All plots/results should be visible such that the notebook do not have to be run. But the code in the notebook should reproduce the plots/results if we choose to do so.\n",
        "*   All tables and other additional information should be included in this notebook.\n",
        "*   Before submitting, make sure that your code can run on another computer. That all plots can show on another computer including all your writing. It is good to check if your code can run on Google colab.\n",
        "* **Submit your solutions as notebook file (`.ipynb`) and in HTML format (`.html`).** To export this notebook to HTML format click `File` $\\rightarrow$ `Download as` $\\rightarrow$ `HTML`.\n",
        "\n",
        "> **Note:** Training neural networks is computationally demanding and may take  time if you run it on your laptop. Running the code in Google Colab will likely be faster and you can even get access to a GPU.\n",
        "\n",
        "> **Note:** To enable GPU hardware accelartion in Google Colab, click the `Change runtime type` field in the `runtime` drop-down menu, then choose `GPU` under hardware acceleration.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hampusgs/machine_learning/blob/main/2021/HW3_2021.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8qum58psQZC"
      },
      "source": [
        "## Required software\n",
        "\n",
        "For this assignment you will need to install the following Python packages:\n",
        "\n",
        "- `pytorch`: Installation instructions can be found on the [pytorch homepage](https://pytorch.org/get-started/locally/) (make sure that you install it together with CUDA to enable GPU acceleration)\n",
        "- `torchvision`: Typically installed with pytorch\n",
        "- `numpy`: The fundamental package for scientific computing with Python (so fundamental that there is a [Nature review](https://www.nature.com/articles/s41586-020-2649-2) on it) \n",
        "- `pandas`: Data analysis and manipulation tool\n",
        "- `matplotlib`: Visualization with Python\n",
        "- `pillow`: Image library to handle PIL images\n",
        "- `catsndogs` and `camels`: The data sets we will be working with. To install them, run: `pip install catsndogs camels`\n",
        "\n",
        "> **Note:** In Google Colab you can install packages using   `!pip  <package_name>`\n",
        "\n",
        "> **Note:** In Google Colab several of these packages are preinstalled but it is a good habit to check if all required packages are installed beforehand and the installed versions of packages. Use `!pip list` to list packages installed by pip on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gjj2fzUsQZH"
      },
      "source": [
        "# Assignment 3\n",
        "# Theoretical exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7FVxRResQZI"
      },
      "source": [
        "## [Exercise 1: Backpropagation by hand, 2 point]\n",
        "\n",
        "Consider the simple feed-forward neural network depicted in the figure below. This network\n",
        "consists of an input layer $\\mathbf{y}_0 = \\mathbf{x}$ with 3 features,  one hidden layer\n",
        "with activations $\\mathbf{y}_1$ and a two-dimensional output layer with activations $\\mathbf{y}_2 = \\hat{\\mathbf{y}}$.\n",
        "\n",
        "![Neural network illustration.](https://raw.githubusercontent.com/hampusgs/machine_learning/main/2021/simpleNN.png)\n",
        "\n",
        "The activations of a layer $k$ are computed by applying a linear transformation given by the weight matrix\n",
        "$\\mathbf{W}^{(k)}$ to the input activations $\\mathbf{y}_{k - 1}$ producing the intermediate values $\\mathbf{z}_k$:\n",
        "\n",
        "$$\n",
        "z_{k , i} = \\sum_j  y_{k - 1,j} w^{(k)}_{j, i}\\\\\n",
        "$$\n",
        "\n",
        "This is followed by the element-wise application of the layers'\n",
        "activation function $g_k$ to the intermediate values $\\mathbf{z}_k$:\n",
        "\n",
        "$$\n",
        "y_{k,j} = g_{k} (z_{k,j})\n",
        "$$\n",
        "\n",
        "> **Note:** Here we use the same notation as in the lecture slides, but several different notations exist.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2hk9xN-sQZK"
      },
      "source": [
        "### 1, a)\n",
        "\n",
        "Given the derivatives of an loss term $E$ with respect to the activations of the output neurons \n",
        "$\\frac{dE}{dy_{2,j}}$, derive expressions for the derivatives of the error term with respect to the weights\n",
        "$w^{(k)}_{i,j}$ and activations $y_{k,j}$ of the remaining layers of the network. Simplify as much as possible.\n",
        "\n",
        "Also, to simplify the results, you are encouraged to reuse derivatives you have already computeds in the expressions for the  downstream derivatives.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{dE}{dw^{(2)}_{i, j}} = \\: ? \\\\\n",
        "\\frac{dE}{dy_{1,j}} = \\: ? \\\\\n",
        "\\frac{dE}{dw^{(1)}_{i, j}} = \\: ? \\\\\n",
        "\\frac{dE}{dy_{0,j}} = \\: ? \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "If your calculations are correct, you should see that you can express the derivatives of the error function \n",
        "around a given layer in the network using the derivatives from the next higher layer. This yields a simple\n",
        "recipe to successively compute the gradients in a feed forward neural network by starting at the last layer and\n",
        "then computing the gradients layer-by-layer as you move backwards through the network. This method is commonly\n",
        "referred to as **backpropagation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4hV-XWQsQZL"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiwS-uScsQZN"
      },
      "source": [
        "## [Exercise 2: Counting parameters in networks, 1.5 point]\n",
        "\n",
        "### 2, a) (0.5 point)\n",
        "Imagine you apply a two layer fully connected network to a 32x32 rgb image. The hidden layer has dimension 512 and the output is of size 10. How many parameters are necessary? Include the bias parameters. Show your calculations.\n",
        "\n",
        "### 2, b) (1 point)\n",
        "\n",
        "Apply the following network to the same image, how many parameters are needed? Include bias parameters. Show your calculations.\n",
        "\n",
        "* Convolutional layer with 16 5x5 filters (stride 1).\n",
        "\n",
        "* Max pooling layer (2x2) (stride 2).\n",
        "\n",
        "* Convolutional layer with 32 5x5 filter (stride 1).\n",
        "\n",
        "* Fully connected layer to ouput of size 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1_rmmx1sQZO"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe8e0hW8sQZR"
      },
      "source": [
        "## [Excercise 3: Calculating output dimensions of a convolutional layer, 0.5 point]\n",
        "\n",
        "Assume you apply a convolutional layer with 8 3x3 filters (stride 2) on a rgb 29x13 image. What will the dimensions of the output be (assuming no padding is done in the convolution)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYeIyWp4sQZS"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuwRTbSZsQZT"
      },
      "source": [
        "## [Excercise 4: Applying a filter to an image, 0.5 point]\n",
        "\n",
        "\\begin{align}\n",
        "\\text{Image:} \n",
        "\\begin{bmatrix}2 & 2 & -2 & 3 \\\\\n",
        "               -1 & 1 & -2 & 1 \\\\\n",
        "               1 & 3 & 1 & 1 \\\\\n",
        "               -1 & 2 & 1 & 1 \n",
        "\\end{bmatrix}\n",
        "\\ \\ \n",
        "\\text{Filter:}\n",
        "\\begin{bmatrix}-1 & 1\n",
        "\\\\-1 & 1\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Convolve the filter over the image and apply ReLU, use a stride of 2 with a bias of -2. Give an explanation for the output, what is the filter detecting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoRPX0wNsQZW"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qESq7OMosQZY"
      },
      "source": [
        "## [Exercise 5: Recurrent neural networks, 1.5 point]\n",
        "\n",
        "Consider a RNN, which maps a sequence of inputs $\\mathbf{x}_0, \\mathbf{x}_1, \\ldots$ to a sequence of outputs $\\mathbf{y}_0, \\mathbf{y}_1, \\ldots$. At each step $t$, the hidden state $\\mathbf{h}_t$ and output $\\hat{\\mathbf{y}}_t$ of the RNN are computed using\n",
        "\\begin{align}\n",
        "  \\mathbf{h}_t &= \\tanh(\\mathbf{W}_{\\mathbf{h}\\mathbf{h}} \\ \\mathbf{h}_{t -1} + \\mathbf{W}_{\\mathbf{x}\\mathbf{h}}\\ \\mathbf{x}_t ) \\\\\n",
        "  \\hat{\\mathbf{y}}_t &= \\mathbf{W}_{\\mathbf{h}\\mathbf{y}}\\ \\mathbf{h}_t\n",
        "\\end{align}\n",
        "  \n",
        "### 5, a) (0.5 Point)\n",
        "\n",
        "The RNN is applied to a sequence of two inputs $\\mathbf{x}_0, \\mathbf{x}_1$. Write down analytic expressions for the corresponding outputs $\\mathbf{y}_0, \\mathbf{y}_1$ assuming the initial hidden state to be the zero vector.\n",
        "\n",
        "### 5, b) (0.5 Point)\n",
        "\n",
        "Assume that the vectors $\\mathbf{x}_0, \\mathbf{x}_1$ have a length of 8, the hidden state $\\mathbf{h}_t$ a length of $16$ and the output vectors $\\hat{\\mathbf{y}}_0, \\hat{\\mathbf{y}}_1$ a length of 1. How many learnable parameters does the RNN described above have? How does this number depend on the length of the input sequence?\n",
        "\n",
        "### 5, c) (0.5 Point)\n",
        "\n",
        "Describe two diffculties that can occur when training RNNs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIX1e1tZsQZZ"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g17D4odtsQZZ"
      },
      "source": [
        "# Practical exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3RdupcBsQZa"
      },
      "source": [
        "# Image Classification\n",
        "\n",
        "In this practical part of the assignment, you will develop a classification algorithm that predicts whether an image contains a cat or a dog. You wil do this using the `pytorch` deep learning framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDzzdoH3sQZb"
      },
      "source": [
        "## The data\n",
        "\n",
        "The data that you will be using in this exercise consists of images of cats and dogs. The dataset is available through the `catsndogs` Python package. The package automatically downloads the data and provides access to the image files in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "udURJpsTsQZc"
      },
      "source": [
        "from catsndogs.training import cats, dogs # The lists of cat and dog images."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIMUJd-5sQZf"
      },
      "source": [
        "Below, a few examples of the images in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KklFROcsQZh"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "f, axs = plt.subplots(2, 4, figsize = (8, 4))\n",
        "for i in range(4):\n",
        "    img = np.random.choice(cats)\n",
        "    ax = axs[0, i]\n",
        "    ax.set_title(\"A Cat\")\n",
        "    ax.imshow(Image.open(img))\n",
        "for i in range(4):\n",
        "    img = np.random.choice(dogs)\n",
        "    ax = axs[1, i]\n",
        "    ax.set_title(\"A Dog\")\n",
        "    ax.imshow(Image.open(img))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHlBoVZSsQZi"
      },
      "source": [
        "## Getting started with pytorch\n",
        "\n",
        "The following part provides a brief introduction to the fundamentals of `pytorch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGf6l9CesQZi"
      },
      "source": [
        "### Why pytorch?\n",
        "\n",
        "As most other popular deep learning frameworks, `pytorch` provides the following features:\n",
        "\n",
        "- automatic differentiation,\n",
        "- GPU support,\n",
        "- flexible composition of neural network models,\n",
        "- numerous pre-defined network components and optimization methods.\n",
        "\n",
        "Pytorch strikes a good balance between flexibility, usability and performance, making it well suited for an introductory exercise as this one. There of course exist quite a few alternative frameworks, but the general concepts that you will learn in this exercise will apply also for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82A8gjvxsQZj"
      },
      "source": [
        "### Accessing documentation\n",
        "\n",
        "Note that you can access source code documentation from inside the jupyter notebook using `?` and the `help` function. Documentation of the different torch modules can be found on the [pytorch home page](https://pytorch.org/docs/stable/index.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fA4DfJt5sQZk"
      },
      "source": [
        "import torch\n",
        "help(torch.tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5AhIqxnsQZn"
      },
      "source": [
        "##### Tensors\n",
        "\n",
        "Tensors are a fundamental concept of `pytorch`, as well as most other deep learning frameworks. A tensor  designates a collection of elements that are organized on a multi-dimensional grid. You may think of them as a generalization of vectors or matrices: The elements in a vector are organized along 1 dimension, whereas in a matrix they are organized along 2 dimensions.\n",
        "\n",
        "A typical application of tensors is to hold images. As an example, we can load an image of a dog into a `torch.tensor`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZhqtxiRsQZn"
      },
      "source": [
        "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
        "image_name = np.random.choice(dogs)\n",
        "dog = to_tensor(Image.open(image_name))\n",
        "print(\"The size of 'dog' is:\", dog.size())\n",
        "dog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVF029WisQZo"
      },
      "source": [
        "It becomes interesting when we start applying mathematical operations to tensors. For example we can compute the average of a cat and a dog. Note that all common mathematical operators (`+`, `-` `*`, `**`, ...) are defined on tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4E2XwcsQZo"
      },
      "source": [
        "image_name = np.random.choice(cats)\n",
        "cat = to_tensor(Image.open(image_name))\n",
        "plt.imshow(to_pil_image(0.5 * (cat + dog)))\n",
        "plt.title(\"A cat/dog average\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFqsHb4PsQZo"
      },
      "source": [
        "### Common tensor operations\n",
        "\n",
        "There are many operations available on tensors and most of them follow the names used in `numpy`. In general, you can expect there to be an operation for most tasks at hand, so make sure you check the `pytorch` documentation search engine before you start cooking up something on your own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRnTvIq_sQZp"
      },
      "source": [
        "#### Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZb50b23sQZp"
      },
      "source": [
        "import torch\n",
        "ones = torch.ones(10, 10)\n",
        "zeros = torch.zeros(10, 10)\n",
        "rand = torch.randn(10, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E06y6vZGsQZq"
      },
      "source": [
        "#### Mathematical operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVC11klFsQZq"
      },
      "source": [
        "rand1 = torch.add(ones, rand)\n",
        "p = torch.sigmoid(rand)\n",
        "exp = torch.exp(rand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOo2rQ9ssQZq"
      },
      "source": [
        "#### Type conversions\n",
        "\n",
        "As with `numpy.ndarray`s, the elements in a `torch.tensor` can have different data types. You can convert between different data types using the `to` member function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tmz_m39sQZr"
      },
      "source": [
        "print(\"The data type of p:\", p.dtype)\n",
        "p_short = p.to(torch.short)\n",
        "print(\"The data type of p_short:\", p_short.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbFf-yaWsQZr"
      },
      "source": [
        "For ML tasks you typically want to use [single-precision floating point numbers](https://en.wikipedia.org/wiki/Single-precision_floating-point_format) (`torch.float32`). In general you will not have to worry too much about the data type, however, older versions of `pytorch` will throw errors when operations are performed on tensors with different numeric types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7-A4NbmsQZr"
      },
      "source": [
        "p + p_short # Fails on older version of pytorch."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wskv58XysQZr"
      },
      "source": [
        "p2 = p + p_short.float() # short for p_short.to(torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIJnwpXLsQZs"
      },
      "source": [
        "#### Conversion from and to numpy arrays\n",
        "\n",
        "numpy arrays can be converted directly to pytorch tensors using the `torch.tensor` function.\n",
        "\n",
        "Converting `pytorch` tensors to numpy arrays can be done using the `numpy()` member function. If `pytorch` tracks the gradient of a tensor, then you will also need to call the `detach()` member function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi503NQTsQZs"
      },
      "source": [
        "t_numpy = np.random.rand(2, 2)\n",
        "t = torch.tensor(t_numpy)\n",
        "print(\"Type of t:\", type(t_numpy))\n",
        "print(\"Type of t_pytorch:\", type(t))\n",
        "print(\"Type of t_pytorch.numpy():\", type(t.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OngnHVEsQZs"
      },
      "source": [
        "t.requires_grad = True\n",
        "#t.numpy() # Doesn't work\n",
        "t.detach().numpy() # Works"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKwUOv3usQZt"
      },
      "source": [
        "### Automatic differentiation\n",
        "\n",
        "One of the core strengths of pytorch is that it let's you compute complex mathematical operations on tensors and compute their derivatives. Remember, that this is an important part of training neural networks: In order to minimize the loss function using gradient descent, it is of course required to first compute the gradients. Luckily, `pytorch`'s `autograd` module can take care of all the complicated calculations that are required to compute the gradients of neural networks.\n",
        "\n",
        "Computing gradients w.r.t to a given tensor involves the following steps:\n",
        "1. Create a tensor and set the `requires_grad` attribute to `True`,\n",
        "2. apply mathematical operations,\n",
        "3. call the `backward()` function of the result tensor to compute the gradients.\n",
        "\n",
        "> *Note:* Step 1 is not required for parameters of networks, whose gradients are computed by default when the model is in training mode.\n",
        "\n",
        "As an example, take the following operation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STk8QffKsQZt"
      },
      "source": [
        "x = torch.linspace(-4, 4, 101, requires_grad=True)\n",
        "y = torch.sigmoid(x)\n",
        "z = y.sum()\n",
        "z.backward()\n",
        "dzdx = x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cguRn7jGsQZu"
      },
      "source": [
        "f, ax = plt.subplots(1, 1)\n",
        "ax.plot(x.detach().numpy(),\n",
        "        y.detach().numpy(),\n",
        "        label = \"$\\sigma(x)$\")\n",
        "ax.plot(x.detach().numpy(),\n",
        "        dzdx.numpy(),\n",
        "        label = \"$?(x)$\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"x\")\n",
        "ax.set_ylabel(\"y\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-xTEsagsQZu"
      },
      "source": [
        "## [Exercise 1: Derivatives of activation functions, 0.5 point] \n",
        "\n",
        "Write down analytical expressions for the function $\\sigma(x)$ and $?$ shown above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZyH5tq3sQZu"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAbnPvE9sQZu"
      },
      "source": [
        "### GPU acceleration\n",
        "\n",
        "Training complex networks is a computationally demanding task. To shorten training times, caluclations are typically performed on specialized hardware that was traditionally used to render 3D graphics on computers, so called graphic processing units (GPUs) or graphic cards. GPUs are in general more efficient in performing  highly-parallel computational tasks than CPUs, which are the chips that perform all 'standard' calculations in a PC. In `pytorch`, all oprations on tensors can be performed on a GPU using NVIDIA's CUDA computing platforms (https://en.wikipedia.org/wiki/CUDA).\n",
        "\n",
        "The different processors that can be used for calculations, i.e. CPU or GPU, are represented in `pytorch` as devices. Each tensor has an associated device on which its data is located.\n",
        "The default device is represented by `torch.device(\"cpu\")`. Hence by default, all calculations are executed on the CPU.  In order to be able to perform calculations on a tensor using a GPU, you need to move its data to the GPU's memory.\n",
        "\n",
        "\n",
        "> **Note:** If you are using Google Colab, you may need to enable GPU hardware acceleration by `Go to Menu > Runtime > Change runtime` and change hardware acceleration to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW1ZXgaBsQZv"
      },
      "source": [
        "# First check if CUDA is available.\n",
        "print(torch.cuda.is_available())\n",
        "cuda = torch.device(\"cuda\")\n",
        "cpu = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HRgWsH3sQZw"
      },
      "source": [
        "Below, we will perform a quick demonstration of how much faster matrix multiplication becomes when executed on a  GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzITjlBEsQZy"
      },
      "source": [
        "W = torch.rand(512, 512)\n",
        "def matmul_cpu():\n",
        "    result = W\n",
        "    for i in range(10):\n",
        "        result = torch.matmul(W, result)\n",
        "    return result\n",
        "        \n",
        "%time matmul_cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxaPgiUGsQZy"
      },
      "source": [
        "W_cuda = W.to(cuda)\n",
        "\n",
        "def matmul_gpu():\n",
        "    result = W_cuda\n",
        "    for i in range(10):\n",
        "        result = torch.matmul(W_cuda, result)\n",
        "    return result\n",
        "        \n",
        "matmul_gpu() # First time using GPU can incur some overhead.\n",
        "%time matmul_gpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1gX6jcEsQZz"
      },
      "source": [
        "The `%time` command displays CPU and Wall time for the execution of the two functions. The CPU time is split up in `user` time, which is the time spent executing only your code, and `sys` time, which is the time spent executing system kernel code required for example to load data from disk. Note that the CPU time is computed per core, so when your code runs on multiple cores the resulting CPU time is the sum of the time each core spends computing.\n",
        "\n",
        "The wall time shows the total time that it took to execute the function. Since CPU time is calculated per core, the wall time can actually be lower than the CPU time for code that is executed on multiple CPUs in parallel.\n",
        "\n",
        "To compare the absolute execution time for the two functions it is therefore most meaningful to compare the displayed wall times. As you should see from them, calculating the matrix power on the GPU is substantially faster than calculating it on the CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8OhpNhnsQZ0"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "To train a network on the `catsndogs` dataset, we need to load the images into tensors. The `catsndogs.training` module has an attribute `folder`, which points to the root folder containing the training data. The root folder contains a `cat` and a `dog` folder which holds the images of cats and dogs, respectively.\n",
        "\n",
        "\n",
        "Using the `torchvision.datasets.ImageFolder` class, data that is organized in a folder structure like this can be turned directly into a dataset for training ML algorithms. The dataset provides access to the images as input and as an integer representations of the class labels as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxasqYWasQZ0"
      },
      "source": [
        "from catsndogs.training import folder\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "images = ImageFolder(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFR2NjmusQZ1"
      },
      "source": [
        "You can load a sample from the training data by indexing the `images` object, which will return a tuple `(image, label)` containing the loaded image and corresponding label, which is 0 for cat and 1 for dog."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnN33AsusQZ2"
      },
      "source": [
        "image, label = images[0]\n",
        "plt.imshow(image)\n",
        "print(\"The type of image is:\", type(image))\n",
        "print(\"The label is:\", label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZNu6rvksQZ3"
      },
      "source": [
        "However, as the code above shows, the type of the loaded image is a `PIL` image and not a tensor. To automatically transform the loaded image into a tensor, you can make use of the `transformation` parameter of the `ImageFolder` class.\n",
        "\n",
        "The cell below adds a composition of two transforms to the dataset. The two transforms are applied sequentially to the image object that would otherwise be returned from the dataset. The first transform turns the image into a torch tensor and the second transform normalizes the image values so that they lie in the range $[-1, 1]$.\n",
        "\n",
        "> Note: Input data that is not centered around zero can cause convergence problems during training, so it is usually a good idea to normalize input data to a range centered around 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU8kbTHYsQZ3"
      },
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "\n",
        "transform = Compose([ToTensor(),\n",
        "                     Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "images = ImageFolder(folder, transform=transform)\n",
        "image, label = images[0]\n",
        "print(\"Type of image is now:\", type(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9qFeihfsQZ4"
      },
      "source": [
        "# This function inverts the transformation of the input images.\n",
        "def to_image(tensor):\n",
        "    tensor = 0.5 * (tensor + 1.0)\n",
        "    return to_pil_image(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkDAAIDdsQZ5"
      },
      "source": [
        "For the training, we further split the data into training and validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niANDToGsQZ5"
      },
      "source": [
        "n_train = int(0.9 * len(images))\n",
        "n_val = len(images) - n_train\n",
        "training_data_catsndogs, validation_data_catsndogs = torch.utils.data.random_split(images, (n_train, n_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOyphTcnsQZ6"
      },
      "source": [
        "## [Exercise 2: Training a fully-connected network, 5.5 points]\n",
        "## Defining a neural network model\n",
        "\n",
        "Neural networks in `pytorch` are represented using the [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) class. The typical way to define a neural network model is to define a new class that inherits from the `Module` class.\n",
        "\n",
        "### 2, a) (1 points)\n",
        "\n",
        "Inspect the code given below and, using the documentation of the [`torch.nn`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) module, answer the following questions:\n",
        "- What is the architecture of instances of the `FullyConnected` class?\n",
        "- What activations functions are applied in the hidden layers?\n",
        "- What activation function is used for the output?\n",
        "- How are the parameters of the network initialized? Why is this important to know?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5j2D4kKsQZ7"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class FullyConnected(nn.Module):\n",
        "    \"\"\"\n",
        "    Usually, this docstring should contain useful information about this\n",
        "    class but this would make the exercise too easy.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_features,\n",
        "                 width):\n",
        "        \"\"\"\n",
        "        Create a new mysterious network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.input_features = input_features\n",
        "        self.fc_1 = nn.Linear(input_features, width)\n",
        "        self.fc_2 = nn.Linear(width, width)\n",
        "        self.fc_3 = nn.Linear(width, width)\n",
        "        self.fc_4 = nn.Linear(width, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        The forward method required by nn.Module base class.\n",
        "        \"\"\"\n",
        "        x = x.flatten(1, -1)\n",
        "        x = self.fc_1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc_2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc_3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc_4(x)\n",
        "        return x\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxfYAeNOsQZ9"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdSoi_EesQZ-"
      },
      "source": [
        "## The training loop\n",
        "\n",
        "In the cell below you find code for a typical training loop in `pytorch`. \n",
        "\n",
        "### 2, b) (1 point)\n",
        "\n",
        "Look at the function below and answer the following questions: \n",
        "\n",
        "- Most of the actual training functionality is abstracted away in the arguments provided to the function. For each of the arguments, describe what tasks the corresponding object has to perform so that this method can be used to train a neural network.\n",
        "- What functions do the calls `model.train()` and `model.eval()` have? Why are these calls important?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-OSZLy_sQZ_"
      },
      "source": [
        "def train_epoch(training_loader,\n",
        "                validation_loader,\n",
        "                model,\n",
        "                loss,\n",
        "                optimizer,\n",
        "                device):\n",
        "    \"\"\"\n",
        "    Again, this should be a useful docstring, but that would\n",
        "    give away the answer for the exercise.\n",
        "    \"\"\"\n",
        "    \n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    \n",
        "    training_loss = 0.0\n",
        "    n = len(training_loader)\n",
        "    \n",
        "    for i, (x, y) in enumerate(training_loader):\n",
        "        \n",
        "        # Set gradients to zero.\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Move input to device\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        # Predict output, compute loss, perform optimizer step.\n",
        "        y_pred = model(x)\n",
        "        l = loss(y_pred, y.view(-1, 1).float())\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        training_loss += l.item()\n",
        "        print(\"Batch ({} / {}): Loss {:.2f}\".format(i, n, l.item()), end=\"\\r\")\n",
        "        \n",
        "    training_loss /= n\n",
        "        \n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    n = len(validation_loader)\n",
        "    \n",
        "    for i, (x, y) in enumerate(validation_loader):\n",
        "        # Move input to device\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        # Predict output, compute loss, perform optimizer step.\n",
        "        y_pred = model(x)\n",
        "        l = loss(y_pred, y.view(-1, 1).float())\n",
        "        \n",
        "        validation_loss += l.item()\n",
        "    validation_loss /= n\n",
        "    \n",
        "    model.to(torch.device(\"cpu\"))\n",
        "    \n",
        "    return (training_loss, validation_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvc4ouO9sQZ_"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a74RqdjsQaA"
      },
      "source": [
        "## The optimizer object\n",
        "\n",
        "In the code above the optimization method was hidden in the `optimizer` object. To understand how to write a suitable optimizer, you first need to understand a bit more about the role of `Module` objects in `pytorch`. The `torch.nn.Module` class is the base class for all neural networks and the components that make up neural networks. Module objects typically have trainable parameters. These trainable parameters of a module can be accessed via its `parameters()` member function. When a module contains attributes that are themselves `Module` instances, then  the `parameters()` function of the containing module will automatically list the trainable parameters of its `Module` attributes.\n",
        "\n",
        "In order to  train a network, the optimizer needs to be aware of the module's parameters. In `pytorch` an optimizer object therefore always needs to be instantiated with a list of parameters that should be trained. In addition to that, an optimizer typically provides a function to set the gradients of the module parameters to zero. This is because gradients in pytorch are accumulated between consecutive calls to the `backward()` function.\n",
        "This makes it necessary to set the gradients to zero between to training iterations.\n",
        "\n",
        "### 2, c)  (0.5 points)\n",
        "\n",
        "Complete the code below so that the `step` method of the `SGD` class performs gradient descent on the provided list of parameters.\n",
        "\n",
        "> **Hint 1:** The `parameters()` member function returns a list of tensors representing the weight matrices and bias vectors in a network. Given a tensor `p`, you can access its gradients using the `p.grad` attribute.\n",
        "\n",
        "> **Hint 2:** Because of the way `pytorch`'s autograd function works, changing the  value of a parameter `p` has to be done using its `p.data` attribute:\n",
        "\n",
        "```\n",
        "p.data = ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OekRcXuDsQaA"
      },
      "source": [
        "class GradientDescent():\n",
        "    \"\"\"\n",
        "    A gradient descent optimizer.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 parameters,\n",
        "                 learning_rate):\n",
        "        \"\"\"\n",
        "        Create a gradient descent optimizer.\n",
        "        \n",
        "        Arguments:\n",
        "            parameters: Iterable providing the parameters to optimize.\n",
        "            learning_rate: The learning rate to use for optimization.\n",
        "        \"\"\"\n",
        "        self.parameters = list(parameters)\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "    def zero_grad(self):\n",
        "        for p in self.parameters:\n",
        "            if not p.grad is None:\n",
        "                p.grad.zero_()\n",
        "        \n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Perform a gradient descent step on parameters associated to this optimizer.\n",
        "        \"\"\"\n",
        "        for p in self.parameters:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC9Qp4mPsQaA"
      },
      "source": [
        "## Training the network\n",
        "\n",
        "With the optimizer, the model and the training loop in place we are close to being able to start training the network, however a few details remain to be sorted out.\n",
        "\n",
        "The `training_data_catsndogs` and `validation_data_catsndogs` object defined above can be used to iterate over the data, but only on a per sample basis. For the training of a neural network, however, we typically want to iterate through the data in batches. To take care of this, `pytorch` provides the `DataLoader` class, which can be used to batch and shuffle existing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsOX_DPTsQaA"
      },
      "source": [
        "from  torch.utils.data import DataLoader\n",
        "training_loader_catsndogs = DataLoader(training_data_catsndogs, batch_size=32, shuffle=True)\n",
        "validation_loader_catsndogs = DataLoader(validation_data_catsndogs, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4x-85c0sQaB"
      },
      "source": [
        "Next, we need to choose a suitable training loss to minimize.\n",
        "\n",
        "### 2, d) (0.5 points)\n",
        "\n",
        "Choose a suitable loss function from the [`torch.nn`](https://pytorch.org/docs/stable/nn.html) module and assign an instance of it to the loss variable in the code cell below\n",
        "\n",
        "> **Hint:** Note that in the `train_epoch` function defined above loss function is applied **directly** to the output of the network. In your choice of the loss function you thus need to consider the output activation of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToRzHzR7sQaB"
      },
      "source": [
        "loss = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg72IE94sQaB"
      },
      "source": [
        "Finally, we choose the device to run the training on. If available, you should use a GPU because it will be substantially faster.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWUg8rVcsQaC"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda') # Default CUDA device\n",
        "else:\n",
        "    device = torch.device('cpu')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6_esRP1sQaC"
      },
      "source": [
        "### 2, e) (1 point)\n",
        "\n",
        "Train the neural network for a least 10 epochs, then reduce the learning rate and continue training for at least another ten epochs. Plot the resulting training and validation losses, and answer the following question(s):\n",
        "\n",
        "- Was the training successful? Explain why.  \n",
        "- If the training was unsuccessful, give suggestion(s) on what can be done to make the training successful.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jkUXhgHsQaC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IvrTPxqsQaD"
      },
      "source": [
        "#### Your answer here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyrXd6CFsQaD"
      },
      "source": [
        "### 2, f) (1 point)\n",
        "\n",
        "A useful performance metric for binary classification tasks  is the [receiver operating characteristic (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic). Complete the code below and write a function that computes the true positive and false positive rate for varying values of the discrimination threshold $p \\in [0, 1]$. Then, using the code below, plot the ROC. What is the significance of the black, dashed line?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PcrfAnisQaD"
      },
      "source": [
        "def receiver_operating_characteristic(model,\n",
        "                                      validation_loader,\n",
        "                                      ps):\n",
        "    \"\"\"\n",
        "    Computes receiver operating characteristic for given model and\n",
        "    validation data.\n",
        "    \n",
        "    Arguments:\n",
        "        model: The pytorch model to evaluate.\n",
        "        validation_loader: torch DataLoader to use to iterate over validation data.\n",
        "        ps: Iterable containing the values of the discrimination threshold in\n",
        "           increasing order.\n",
        "    Returns:\n",
        "        (fpr, tpr): Tuple containing the false positive rates (fpr) and the true\n",
        "            positive rates as numpy.ndarrays.\n",
        "    \"\"\"\n",
        "    ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXmqStEGsQaE"
      },
      "source": [
        "fpr, tpr = receiver_operating_characteristic(fc, validation_loader_catsndogs, np.linspace(0, 1, 101))\n",
        "\n",
        "def plot_ROC(fpr,tpr):\n",
        "    \"\"\"\n",
        "    Plots ROC curve\n",
        "\n",
        "    Arguments:\n",
        "        fpr: array-like containing false positive rates\n",
        "        tpr: array-like containing true positive rates\n",
        "\n",
        "    \"\"\"\n",
        "    x = np.linspace(0, 1, 101)\n",
        "    f, ax = plt.subplots(1, 1)\n",
        "    ax.plot(x, x, c=\"k\", ls=\"--\")\n",
        "    ax.plot(fpr, tpr)\n",
        "    ax.set_ylabel(\"TPR\")\n",
        "    ax.set_xlabel(\"FPR\")\n",
        "    ax.set_title(\"Receiver operator characteristic\")\n",
        "\n",
        "plot_ROC(fpr,tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lBv6pfXsQaE"
      },
      "source": [
        "#### Your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_BENnKGsQaF"
      },
      "source": [
        "### 2, g) (0.5 point)\n",
        "\n",
        "One way to summarize the receiver operator characteristic (ROC) is to compute the area under the curve. This can be done using the [trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule). Complete the code below and write a function for computing the area under the receiver operator characteristic curve (AUC ROC) using the trapezoidal rule. Then, calculate the area under the ROC-curve in exercise above 2, g) using this function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99u-LibFsQaH"
      },
      "source": [
        "def auc_roc(fpr, tpr):\n",
        "    \"\"\"\n",
        "    Computes area under receiver operating characteristic cruve using the\n",
        "    trapeziodal rule for given false positive and true positive rates.\n",
        "    \n",
        "    Arguments:\n",
        "        fpr: False positive rates.\n",
        "        tpr: True positive rates.\n",
        "        \n",
        "    Returns:\n",
        "        auc_roc: Area under the receiver operating characteristic curve as\n",
        "            float value\n",
        "    \"\"\"\n",
        "    ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwrkHhQqsQaI"
      },
      "source": [
        "Finally, let's look at the prediction for samples from the validation set. Is this what you expected? You do **not** need to write down an answer for this question, but you should always spend some time to reflect on your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA6rG4XGsQaI"
      },
      "source": [
        "def index_to_pet(index):\n",
        "    \n",
        "    if index == 0:\n",
        "        return \"cat\"\n",
        "    else:\n",
        "        return \"dog\"\n",
        "    \n",
        "def plot_results(model, validation_data):\n",
        "    model.to(torch.device(\"cpu\"))\n",
        "    f, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
        "    for i in range(10):\n",
        "\n",
        "        # Make prediction on random validation sample\n",
        "        index = np.random.randint(len(validation_data))\n",
        "        x, y = validation_data[index]\n",
        "        c = torch.sigmoid(model(x.unsqueeze(0))) >= 0.5\n",
        "        x = 0.5 * (x + 1.0)\n",
        "        \n",
        "        ax = axs.ravel()[i]\n",
        "        ax.imshow(to_pil_image(x))\n",
        "        title = \"Predicted '{}', \\n True '{}'\"\n",
        "        title = title.format(index_to_pet(c), index_to_pet(y))\n",
        "        ax.set_title(title)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "        \n",
        "plot_results(fc, validation_data_catsndogs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hLVdZ5IsQaJ"
      },
      "source": [
        "## [Exercise 3: Training a convolutional  neural network, 4 points]\n",
        "\n",
        "### 3, a) (2 points)\n",
        "\n",
        "Define and train a convolutional network with the following architecture:\n",
        "- 2D conv. layer: $32$ filters, kernel size $5 \\times 5$, stride 1\n",
        "- ReLU activation function\n",
        "- Max pooling: kernel size $4 \\times 4$, stride 4\n",
        "- 2D conv. layer: $64$ filters, kernel size $5 \\times 5$, stride 1\n",
        "- ReLU activation function\n",
        "- Max pooling: kernel size $2 \\times 2$, stride 2\n",
        "- 2D conv. layer: $128$ filters, kernel size $3 \\times 3$, stride 1\n",
        "- ReLU activation function\n",
        "- Max pooling: kernel size $2 \\times 2$, stride 2\n",
        "- Fully connected: 512 neurons\n",
        "- ReLU activation function\n",
        "- Fully connected: 512 neurons\n",
        "    \n",
        "\n",
        "> **Hint:** You can find all necessary components to implement the convolutional network in the [`torch.nn`](https://pytorch.org/docs/stable/nn.html) module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6B-VHdHsQaJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtFud3vBsQaK"
      },
      "source": [
        "### 3, b)  (2 points)\n",
        "\n",
        "Tune the network architecture and training routine to achieve a validation error lower than 0.2. Some things you may want to try: \n",
        "- Increasing the complexity of your network (more layers, filters or neurons)\n",
        "- A learning rate schedule\n",
        "- Checkpoints or early stopping\n",
        "- Data augmentation to increase the number of training points\n",
        "- Dropout\n",
        "- Other regularization techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G40_8AFNsQaK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOU9ALK9sQaL"
      },
      "source": [
        "## [Exercise 4: Evaluation on test set, 1 points]\n",
        "\n",
        "Now evaluate the performance of the fully-connected neural network to your best convolutional neural network on the `catsndogs` test data, which is available in `catsndogs.test` module.\n",
        "\n",
        "- Plot ROC curves and compute AUC ROC for both the fully-connected and the convolutional model.\n",
        "- Compute the accuracy of each model for a discimination threshold p = 0.5\n",
        "- Provide a plot, for each model, of 8 images from the test set together with the prediction from the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sNzZs5nsQaL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHUdvkxksQaM"
      },
      "source": [
        "# Time series prediction\n",
        "\n",
        "In this practical part of the assignment you will use RNNs to predict the amount of water flowing in a stream or river, the so-called *streamflow*, from meteorological data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKNUHiHfsQaM"
      },
      "source": [
        "## The data\n",
        "\n",
        "The data that you will be using for the training comes from a scientific dataset named *Catchment Attributes and Meteorology for Large-sample Studies* (CAMELS). It is described in detail in the following paper:\n",
        "\n",
        "A. Newman; K. Sampson; M. P. Clark; A. Bock; R. J. Viger; D. Blodgett, 2014. A large-sample watershed-scale hydrometeorological dataset for the contiguous USA. Boulder, CO: UCAR/NCAR. https://dx.doi.org/10.5065/D6MW2F4D\n",
        "\n",
        "The dataset contains time series of streamflow combined with the most important *meteorological forcings* for the given river or stream. The forcing values describe the most important meteorological processes that determine the streamflow. The princpial forcing is of course precipitation, i.e. rain and snow, but also the temperature and strength of solar can indirectly influence the streamflow. These forcings have been aggregated over the drainage basin, which is the area upstream of the gauge measuring the streamflow in which precipitation will drain off into the river whose streamflow is being measured.\n",
        "\n",
        "A model that predicts the strength of the flow in a river from meteorological inputs is called a run-off model.  Important applications of run-off models are predicting floods or analysing the impact of climate change on the stream and its surroundings.\n",
        "\n",
        "In this exercise you will use the streamflow dataset to develop your own run-off model. For this you will use data from a single gauge, identified by the ID `13331500`. The plot below displays the location of the gauge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "685NeHcHsQaN"
      },
      "source": [
        "import pandas as pd\n",
        "import camels\n",
        "\n",
        "gauge_id = 13331500\n",
        "camels.plot_basin(gauge_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKPdBQgVsQaO"
      },
      "source": [
        "The `camels` package provides a Python interface for the streamflow data. Using the `camels.pytorch.Streamflow` class you can access the time series data directly as `pytorch` tensors.\n",
        "\n",
        "The available data spans the time range from 1980 to 2014. Of that, the first 26 years are used as training data, years 2006 to 2010  as validation data and years 2010 to 2014 as testing data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvQPdx4LsQaO"
      },
      "source": [
        "from camels.pytorch import Streamflow\n",
        "training_data_camels = Streamflow(gauge_id, \"training\")\n",
        "validation_data_camels = Streamflow(gauge_id, \"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLrrYaCesQaP"
      },
      "source": [
        "The plot below gives an overview over a period of three years from the training data. The first three panels show the six meteorological forcings that are the inputs for modeling the streamflow:\n",
        "- length of the day\n",
        "- strength of incoming solar radiation\n",
        "- precipitation\n",
        "- (water) vapor pressure, i.e. the amount of water vapor in the air\n",
        "- daily minimum temperature\n",
        "- daily maximum temperature\n",
        "\n",
        "The lowest panel shows the measured streamflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wo86wCTsQaR"
      },
      "source": [
        "from datetime import datetime\n",
        "start = datetime(2000, 1, 1, hour=0)\n",
        "end = datetime(2003, 1, 1, hour=0)\n",
        "training_data_camels.plot_overview(start, end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKwyAK6ssQaS"
      },
      "source": [
        "## [Exercise 5] (1 point) \n",
        "\n",
        "Describe any patterns you see in the time series of forcings and streamflow shown above. Provide a simple description of the physical processes that relate the forcings (input) to the streamflow (output)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asRf4IlLsQaS"
      },
      "source": [
        "#### Your answer here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59WemSbwsQaT"
      },
      "source": [
        "### Training and testing data\n",
        "\n",
        "The `Streamflow` dataset provides sequences of a length of 400 days of meteorological forcings and corresponding streamflows as samples. The `data_loader` member function can be used to instantiate `pytorch` dataloaders with a given batch size.\n",
        "\n",
        "> **Note 1:** Input and outputs in the dataset are all normalized to have mean 0 and standard deviation 1. For simplicity, we will from now on consider forcings and outputs in normalized units instead of the units given in the plot above.\n",
        "\n",
        "> **Note 2:** Pytorch expects tensors of sequences to have the elements in the sequence along the first dimension and the batch elements along the second. A tensor containing a batch of 8 samples from the `Streamflow` data thus\n",
        "has shape `(400, 8, 6)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARA0VGMPsQaT"
      },
      "source": [
        "training_loader_camels = training_data_camels.data_loader(batch_size=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTJP5ueQsQaT"
      },
      "source": [
        "## [Exercise 6] (2 points)\n",
        "\n",
        "### 6, a) (1 point)\n",
        "\n",
        "Write a custom `torch.nn.Module` subclass that implements the basic RNN from theoretical exercise 5 **without using the predefined `nn.RNN` class provided by `pytorch`**. Include the bias terms for the mappings from input to hidden state, hidden state to hidden state, and hidden state to output. This means\n",
        "that for step $t$, the hidden state $h_t$ and output $\\hat{y}_t$ should be given by:\n",
        "\n",
        "\\begin{align}\n",
        "  h_t &= \\tanh( \\mathbf{W}_{xh}\\ x_t + \\theta_{xh} + \\mathbf{W}_{hh} \\ h_{t - 1} + \\theta_{hh}) \\\\\n",
        "  \\hat{y}_t &= \\mathbf{W}_{hy}\\ h_t + \\theta_y\n",
        "\\end{align}\n",
        "\n",
        "Make the size of the hidden state a parameter of the class constructor.\n",
        "\n",
        "\n",
        "> **Hint 1:** You can use `torch.nn.Linear` layers to implement the linear mappings between input, hidden state, and output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5c5Ni_WsQaT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqLTigp-sQaU"
      },
      "source": [
        "### 6, b) (1 point)\n",
        "\n",
        "Train an instance of your RNN model class using mean squared error (MSE) loss on the streamflow training data. For the hidden state, a size around $64$ is a suitable first choice.\n",
        "\n",
        "Monitor the validation loss by computing the MSE for a single predicted sequence of streamflows for the full validation time range. You can obtain the input and output tensors corresponding to the full validation range by calling the `get_range` member function of `validation_data_camels`:\n",
        "\n",
        "```\n",
        "x,y = validation_data_camels.get_range()\n",
        "```\n",
        "\n",
        "Plot training and validation losses.\n",
        "\n",
        "> **Hint 1:** To train your RNN you are free to use all available `pytorch` functionality. Particularly the [`torch.optim`](https://pytorch.org/docs/stable/optim.html) module can be of interest.\n",
        "\n",
        "> **Hint 2:** As baseline, training using the `Adam` optimizer with a learning rate of $10^{-3}$ for 40 epochs should give a significant reduction in training loss. The reduction in the validation will likely be much smaller.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdOrMjEQsQaU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}